{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').options(header ='true',inferschema ='true').load('D:/jcu/5851/A4/unit_2020.csv')\n",
    "#data = sqlContext.read.format('com.databricks.spark.csv').options(header ='true',inferschema ='true').load('D:/jcu/5851/A4/unit_2020_v2.csv')\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unit description: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select(['unit description','Category'])\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Category|count|\n",
      "+--------+-----+\n",
      "|    EDST|   68|\n",
      "|    MMBA|   65|\n",
      "|    LAWS|   48|\n",
      "|    ACCG|   44|\n",
      "|    COMP|   43|\n",
      "|    TRAN|   41|\n",
      "|    AFCP|   41|\n",
      "|    STAT|   39|\n",
      "|    MGMT|   36|\n",
      "|    PICT|   36|\n",
      "|    SPED|   32|\n",
      "|    AFIN|   32|\n",
      "|    PICX|   32|\n",
      "|    MEDI|   29|\n",
      "|    MKTG|   28|\n",
      "|    PSYN|   27|\n",
      "|    AFCL|   27|\n",
      "|    PHTY|   25|\n",
      "|    MMCC|   25|\n",
      "|    GMBA|   24|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 20 group label and count\n",
    "from pyspark.sql.functions import col\n",
    "data.groupBy('Category').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP method 1 : word count vectors\n",
    "# ML method 1 : Logistic Regression\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    " \n",
    "# inputCol: description\n",
    "# outputCol: stop words removed\n",
    "regexTokenizer2 = RegexTokenizer(inputCol='unit description', outputCol='words', pattern='\\\\W')\n",
    "# stop words\n",
    "#add_stopwords = ['unit','study','course','studies','field','students', 'faculty','staff','be','work','form','this']\n",
    "add_stopwords = ['unit','study','course','studies','field','students', 'faculty','staff','be','work','form','this','that','science','learn','university','is','are']\n",
    "stopwords_remover2 = StopWordsRemover(inputCol='words', outputCol='filtered').setStopWords(add_stopwords)\n",
    "# words vector\n",
    "count_vectors2 = CountVectorizer(inputCol='filtered', outputCol='features', vocabSize=10000, minDF=5)\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol='Category', outputCol='label')\n",
    "pipeline = Pipeline(stages=[regexTokenizer2, stopwords_remover2, count_vectors2, label_stringIdx])\n",
    "# fit the pipeline to documents\n",
    "pipeline_fit = pipeline.fit(data)\n",
    "dataset = pipeline_fit.transform(data)\n",
    "#dataset.filter(dataset['Category'] == 'ACST').select(['filtered','features','Category','label']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count:829\n",
      "Test Dataset Count:371\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "# training / test settingï¼Œ7:3\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "print('Training Dataset Count:{}'.format(trainingData.count()))\n",
    "print('Test Dataset Count:{}'.format(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6020698463852643\n",
      "Running time: 5.412540435791016\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').orderBy('probability', accending=False).show(n=10, truncate=30)\n",
    "\n",
    "# predictionCol: prediction column\n",
    "evaluator2 = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "# accuracy\n",
    "print(\"Accuracy: \" + str(evaluator2.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3633177066932591\n",
      "Running time: 1.7193336486816406\n"
     ]
    }
   ],
   "source": [
    "# NLP method 1 : word count vectors\n",
    "# ML method 2 : Naive Bayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "start_time = time.time()\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "#predictions.filter(predictions['prediction'] == 16) \\\n",
    "#     .select( 'Category', 'probability', 'label', 'prediction') \\\n",
    "#     .orderBy('probability', ascending=False) \\\n",
    "#     .show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36603501384644005\n",
      "Running time: 9.490335464477539\n"
     ]
    }
   ],
   "source": [
    "# NLP method 1 : word count vectors\n",
    "# ML method 3 : Random Forest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol='label', \\\n",
    "                             featuresCol='features', \\\n",
    "                             numTrees=100, \\\n",
    "                             maxDepth=10, \\\n",
    "                             maxBins=64)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "#predictions.filter(predictions['prediction'] == 16) \\\n",
    "#     .select('Category','probability','label','prediction') \\\n",
    "#     .orderBy('probability', ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4568939323939996\n",
      "Running time: 8.052201986312866\n"
     ]
    }
   ],
   "source": [
    "# NLP method 2 : TF-IDF\n",
    "# ML method 1 : Logistic Regression\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "start_time = time.time()\n",
    "hashingTF = HashingTF(inputCol='filtered', outputCol='rawFeatures', numFeatures=10000)\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features', minDocFreq=5)\n",
    "pipeline = Pipeline(stages=[regexTokenizer2, stopwords_remover2, hashingTF, idf, label_stringIdx])\n",
    "pipeline_fit = pipeline.fit(data)\n",
    "dataset = pipeline_fit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    " \n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lr_model = lr.fit(trainingData)\n",
    "predictions = lr_model.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44377322242332906\n",
      "Running time: 3.4365761280059814\n"
     ]
    }
   ],
   "source": [
    "# NLP method 2 : TF-IDF\n",
    "# ML method 2 : Naive Bayes\n",
    "#from pyspark.ml.classification import NaiveBayes\n",
    "start_time = time.time()\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "#predictions.filter(predictions['prediction'] == 16) \\\n",
    "#     .select( 'Category', 'probability', 'label', 'prediction') \\\n",
    "#     .orderBy('probability', ascending=False) \\\n",
    "#     .show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3558465402119936\n",
      "Running time: 11.208366632461548\n"
     ]
    }
   ],
   "source": [
    "# NLP method 2 : TF-IDF\n",
    "# ML method 3 : Random Forest\n",
    "#from pyspark.ml.classification import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol='label', \\\n",
    "                             featuresCol='features', \\\n",
    "                             numTrees=100, \\\n",
    "                             maxDepth=10, \\\n",
    "                             maxBins=64)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "#predictions.filter(predictions['prediction'] == 16) \\\n",
    "#     .select('Category','probability','label','prediction') \\\n",
    "#     .orderBy('probability', ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP method 3 : tagging + TF-IDF\n",
    "# ML method 1 : Logistic Regression\n",
    "import nltk\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#from nltk.stem.porter import *\n",
    "\n",
    "tags = set(['NN','NNS','NNP','NNPS','JJ','VB','VBG','VBN'])\n",
    "\n",
    "def pos_tag(text):\n",
    "    text2 = nltk.word_tokenize(text.lower())\n",
    "    pos_tags = nltk.pos_tag(text2)\n",
    "    ret = []\n",
    "    for word,pos in pos_tags:\n",
    "        if (pos in tags and word not in add_stopwords):\n",
    "            ret.append(word)\n",
    "    ret= sorted(set(ret))\n",
    "    return ret\n",
    "udfValueToList = udf(pos_tag, ArrayType(StringType()))\n",
    "data = data.withColumn('filtered2', udfValueToList('unit description'))\n",
    "\n",
    "\n",
    "hashingTF = HashingTF(inputCol='filtered2', outputCol='rawFeatures', numFeatures=10000)\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features', minDocFreq=5)\n",
    "pipeline = Pipeline(stages=[hashingTF,idf, label_stringIdx])\n",
    "pipeline_fit = pipeline.fit(data)\n",
    "dataset = pipeline_fit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4462921180450076\n",
      "Running time: 217.89178943634033\n"
     ]
    }
   ],
   "source": [
    "# NLP method 3 : tagging + TF-IDF\n",
    "# ML method 1 : Logistic Regression\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(maxIter=30, regParam=0.3, elasticNetParam=0)\n",
    "lr_model = lr.fit(trainingData)\n",
    "predictions = lr_model.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42009022259059275\n",
      "Running time: 195.4695110321045\n"
     ]
    }
   ],
   "source": [
    "# NLP method 3 : tagging + TF-IDF\n",
    "# ML method 2 : Naive Bayes\n",
    "start_time = time.time()\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3451141350948708\n",
      "Running time: 343.14731669425964\n"
     ]
    }
   ],
   "source": [
    "# NLP method 3 : tagging + TF-IDF\n",
    "# ML method 3 : Random Forest\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol='label', \\\n",
    "                             featuresCol='features', \\\n",
    "                             numTrees=100, \\\n",
    "                             maxDepth=10, \\\n",
    "                             maxBins=64)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP method 4 : word2vec\n",
    "# ML method 1 : Logistic Regression\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "#from pyspark.ml.classification import LogisticRegression\n",
    " \n",
    "word2vec = Word2Vec(inputCol=\"filtered\", outputCol=\"features\")\n",
    "#label_stringIdx = StringIndexer(inputCol='Category', outputCol='label')\n",
    "pipeline = Pipeline(stages=[regexTokenizer2,stopwords_remover2,word2vec, label_stringIdx])\n",
    "pipeline_fit = pipeline.fit(data)\n",
    "dataset = pipeline_fit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11781491525923361\n",
      "Running time: 5.182934045791626\n"
     ]
    }
   ],
   "source": [
    "# NLP method 4 : word2vec\n",
    "# ML method 1 : Logistic Regression\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0)\n",
    "lr_model = lr.fit(trainingData)\n",
    "predictions = lr_model.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Error due to minus value\\n# NLP method 4 : word2vec\\n# ML method 2 : Naive Bayes\\nstart_time = time.time()\\nnb = NaiveBayes(smoothing=1)\\nmodel = nb.fit(trainingData)\\npredictions = model.transform(testData)\\n#predictions.filter(predictions[\\'Category\\'] == \\'EDST\\').select(\\'Category\\',\\'prediction\\').#orderBy(\\'probability\\', ascending=False).show(n=10, truncate=30)\\nevaluator = MulticlassClassificationEvaluator(predictionCol=\\'prediction\\')\\nprint(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\\nend_time = time.time()\\nprint(\"Running time: \" + str(end_time - start_time))\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Error due to minus value\n",
    "# NLP method 4 : word2vec\n",
    "# ML method 2 : Naive Bayes\n",
    "start_time = time.time()\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23010140579723676\n",
      "Running time: 60.165497064590454\n"
     ]
    }
   ],
   "source": [
    "# NLP method 4 : word2vec\n",
    "# ML method 3 : Random Forest\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol='label', \\\n",
    "                             featuresCol='features', \\\n",
    "                             numTrees=100, \\\n",
    "                             maxDepth=10, \\\n",
    "                             maxBins=64)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "#predictions.filter(predictions['Category'] == 'EDST').select('Category','prediction').\\\n",
    "#orderBy('probability', ascending=False).show(n=10, truncate=30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4794474837038655\n",
      "Running time: 2362.891200065613\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer2, stopwords_remover2, count_vectors2, label_stringIdx])\n",
    "\n",
    "pipeline_fit = pipeline.fit(data)\n",
    "dataset = pipeline_fit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2])\n",
    "             .addGrid(lr.maxIter, [10, 50, 100])\n",
    "#              .addGrid(idf.numFeatures, [10, 100, 1000])\n",
    "             .build())\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "cv = CrossValidator(estimator=lr,\\\n",
    "                   estimatorParamMaps=paramGrid,\\\n",
    "                   evaluator=evaluator2,\\\n",
    "                   numFolds=10)\n",
    "cv_model = cv.fit(trainingData)\n",
    "predictions = cv_model.transform(testData)\n",
    " \n",
    "# model assessment\n",
    "\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "end_time = time.time()\n",
    "print(\"Running time: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
